{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenWebText EDA (Lightweight)\n",
    "\n",
    "Goal: understand data quality and likely cleaning needs before preprocessing.\n",
    "This notebook stays lightweight (no heavy stats or plots)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load a tiny streaming sample\n",
    "We use streaming to avoid downloading large parquet shards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "SAMPLE_SIZE = 2000\n",
    "ds_stream = load_dataset('openwebtext', split='train', streaming=True)\n",
    "\n",
    "samples = []\n",
    "for i, ex in enumerate(ds_stream):\n",
    "    samples.append(ex)\n",
    "    if i + 1 >= SAMPLE_SIZE:\n",
    "        break\n",
    "\n",
    "print(f'Loaded sample size: {len(samples)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Inspect dataset structure\n",
    "Streaming datasets do not expose full length without iterating through the whole set, so we report the sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sample count (loaded):', len(samples))\n",
    "if samples:\n",
    "    print('Example keys:', list(samples[0].keys()))\n",
    "    print('Example text preview:', samples[0].get('text', '')[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print 20 raw samples (first 1000 chars each)\n",
    "for i, ex in enumerate(samples[:20]):\n",
    "    text = ex.get('text', '')\n",
    "    print(f'--- Sample {i} (first 1000 chars) ---')\n",
    "    print(text[:1000])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Lightweight length stats\n",
    "No heavy stats or plotting; just quick length checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(ex.get('text', '')) for ex in samples]\n",
    "\n",
    "if lengths:\n",
    "    avg_len = sum(lengths) / len(lengths)\n",
    "    print(f'Average length: {avg_len:.1f}')\n",
    "    print(f'Min length: {min(lengths)}')\n",
    "    print(f'Max length: {max(lengths)}')\n",
    "\n",
    "    short_count = sum(1 for l in lengths if l < 200)\n",
    "    short_pct = 100.0 * short_count / len(lengths)\n",
    "    print(f'Short samples (<200 chars): {short_count} ({short_pct:.1f}%)')\n",
    "\n",
    "    long_idxs = sorted(range(len(lengths)), key=lambda i: lengths[i], reverse=True)[:3]\n",
    "    print('--- Extremely long samples (first 1000 chars) ---')\n",
    "    for idx in long_idxs:\n",
    "        print(f'Index {idx}, length {lengths[idx]}')\n",
    "        print(samples[idx].get('text', '')[:1000])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Simple content inspection\n",
    "Quick heuristics for HTML, code-like content, and non-English signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "html_re = re.compile(r'<[^>]+>')\n",
    "code_markers = ['```', '{', '}', ';', 'def ', 'class ', '#include', 'import ']\n",
    "\n",
    "def looks_like_code(text: str) -> bool:\n",
    "    if '```' in text:\n",
    "        return True\n",
    "    brace_count = text.count('{') + text.count('}')\n",
    "    if brace_count >= 10:\n",
    "        return True\n",
    "    marker_hits = sum(1 for m in code_markers if m in text)\n",
    "    return marker_hits >= 3\n",
    "\n",
    "def non_english_heuristic(text: str) -> bool:\n",
    "    if not text:\n",
    "        return False\n",
    "    non_ascii = sum(1 for ch in text if ord(ch) > 127)\n",
    "    return (non_ascii / len(text)) > 0.2\n",
    "\n",
    "html_count = 0\n",
    "code_count = 0\n",
    "non_english_count = 0\n",
    "\n",
    "for ex in samples:\n",
    "    text = ex.get('text', '')\n",
    "    if html_re.search(text):\n",
    "        html_count += 1\n",
    "    if looks_like_code(text):\n",
    "        code_count += 1\n",
    "    if non_english_heuristic(text):\n",
    "        non_english_count += 1\n",
    "\n",
    "print(f'Samples with HTML tags: {html_count}')\n",
    "print(f'Samples that look like code: {code_count}')\n",
    "print(f'Samples with non-English signals: {non_english_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Findings and proposed cleaning rules\n",
    "Fill this in after running the notebook.\n",
    "\n",
    "### Findings\n",
    "- Data quality: _TBD_\n",
    "- Common noise: _TBD_\n",
    "\n",
    "### Proposed cleaning rules\n",
    "- Strip HTML tags\n",
    "- Remove code-heavy samples\n",
    "- Remove very short samples\n",
    "- Filter non-English samples (heuristic)\n",
    "\n",
    "### Noise patterns to watch\n",
    "- Boilerplate/navigation text\n",
    "- Duplicates or near-duplicates\n",
    "- Mixed-language or encoding artifacts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}