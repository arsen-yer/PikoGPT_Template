{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de5acbb1",
   "metadata": {},
   "source": [
    "# EDA+Preprocessing: NLP26 OpenWebText (local download)\n",
    "Load the course split locally (no streaming), cache under dataset/, and inspect a small subset for cleaning decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e4fa943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q datasets tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbc4bd8",
   "metadata": {},
   "source": [
    "### Setting Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5b5fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, pathlib\n",
    "\n",
    "# add repo root to path (handles running from notebooks/)\n",
    "ROOT = pathlib.Path.cwd()\n",
    "if ROOT.name == \"notebooks\":\n",
    "    ROOT = ROOT.parent\n",
    "sys.path.insert(0, str(ROOT))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b064ca",
   "metadata": {},
   "source": [
    "## Installing the Dataset in Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b928fd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falling back to openwebtext because Dataset 'NLP26_OpenWebText' doesn't exist on the Hub or cannot be accessed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ada081ed814490480eb5e2bb144cdd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JustS\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\JustS\\.cache\\huggingface\\hub\\datasets--openwebtext. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16226bb09c634d6c9723bcd1d03b622a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0be9387ea45434bb052bafe8921e05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2696ede6a03847758714bea9b0c9a2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/80 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510f5e3059594925b8a2fbf6d1cfae4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00000-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8e52f026a247b68eed4640dd69a2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00001-of-00080.parquet:   0%|          | 0.00/306M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9267cb317016440783e0cbd27336c756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00002-of-00080.parquet:   0%|          | 0.00/304M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2651f8066794b1e978c5630934d8386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00003-of-00080.parquet:   0%|          | 0.00/304M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2f0f538e564d4abdd3fdb5bfa1f4a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00004-of-00080.parquet:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12042801975c4ce1a9ed9c645b24f5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00005-of-00080.parquet:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f105e956cd214ae48695891dc619c054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00006-of-00080.parquet:   0%|          | 0.00/304M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516e43a84d444ee48e9a10062aaf3b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00007-of-00080.parquet:   0%|          | 0.00/300M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3089d920c41945078e8fa2dda580befc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00008-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180a7321233e40468497b75f3b7b0ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00009-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5ef262a123406a8ce57ff9ae82ee19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00010-of-00080.parquet:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15022d5805644763a1eea02815293bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00011-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bc3291011d41218bb132f23d5fc37d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00012-of-00080.parquet:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0d314807a64f829a2de615fdd7567f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00013-of-00080.parquet:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8103b3474a84202b1243684e107dbbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00014-of-00080.parquet:   0%|          | 0.00/304M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003b09c595ff41be9c5df60960c268a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00015-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d649e255b7d4ea2bacd5eacadfc796e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00016-of-00080.parquet:   0%|          | 0.00/304M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddff1a0059d74353bc8569ac30044dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00017-of-00080.parquet:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e035ff45e49a4a71934feb558a858ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00018-of-00080.parquet:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5261d5db960f40d5b8415d0419b3c216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00019-of-00080.parquet:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7632db21dd3c47ebae8fbe0b78992039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00020-of-00080.parquet:   0%|          | 0.00/304M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d3ef23bd9114f508f51c11178a623fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00021-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4eacd543024502bc96e43211c77bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00022-of-00080.parquet:   0%|          | 0.00/305M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d201bd5f5c5422584608dd673e36a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00023-of-00080.parquet:   0%|          | 0.00/305M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c9c8a075804cba9562e61d7de89669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00024-of-00080.parquet:   0%|          | 0.00/300M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c38df5d84943dfb79a0044f4a2fde6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00025-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd2b920112b43619843107ad733c55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00026-of-00080.parquet:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c3fb4a46d4493f8c6c442753ac90e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00027-of-00080.parquet:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8025d8450774dc0baa2c944a216b2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00028-of-00080.parquet:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd131af6cf594191bba91dd869733274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00029-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8ea86e33ba48fd97bd84e2445d52f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00030-of-00080.parquet:   0%|          | 0.00/299M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6f2626b9cc42b4bc3ece225363051f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00031-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f041c842b3e246f9b68266bae1949b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00032-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085021a2c85b473b84d7413357935b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00033-of-00080.parquet:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb303339c214edfaddab8a68f5068c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00034-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0bca1b617114bb9a9b63528828b786c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00035-of-00080.parquet:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c798b61f64cc4f0591832994b9080e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00036-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb25045e47947558686e0abf508840e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00037-of-00080.parquet:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b559cc3e5764da4971acf44a5078d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00038-of-00080.parquet:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f38595e80bf46fb9ae13e75e491a20e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00039-of-00080.parquet:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b01f86d30749c0a374815e1ad6fcfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00040-of-00080.parquet:   0%|          | 0.00/304M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4558773fa34d0a8f00d874045ace6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00041-of-00080.parquet:   0%|          | 0.00/304M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0f8e2f245a4467bb0d8588a4de8b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00042-of-00080.parquet:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9771765282e4efdbabda73c13cbbc0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00043-of-00080.parquet:   0%|          | 0.00/305M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a30a0acb3f49f291b31ed3b4b24ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00044-of-00080.parquet:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae9640ac10947a49023622c16eea089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00045-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc03f48885745b6b3d76f6b0c8757e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00046-of-00080.parquet:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8aa0b0fa014782a12e4ba2838f8168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00047-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2791d359d2409a8f8d00252b6b78ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00048-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463a848a630646ad9fd0b8425d44955d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00049-of-00080.parquet:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fdb6426c1c14afbad4e8e8954f0aff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00050-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d62716690ba4bb2905fd70ae82a7bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00051-of-00080.parquet:   0%|          | 0.00/305M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2475cee66e6e439997382a84adff91ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00052-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e42e09aa6343d794dc7cf62c29f27e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00053-of-00080.parquet:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314f2c712d644994bb4dbe75188f8728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00054-of-00080.parquet:   0%|          | 0.00/304M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513c872f224241079fcc8d1f33e349e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00055-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0bc88c50414df196265a1c42675439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00056-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b4cf0932154e069f07dfe283afe182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00057-of-00080.parquet:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a932354a5784738b78cc15e665f3d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00058-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa42699bf92242539e03806f4608ed71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00059-of-00080.parquet:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523a62e8fd454a588cffb04195920f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00060-of-00080.parquet:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2869e5ac91845e68a1a30c81ae8490a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00061-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f11d55b43bd41b19069abd1a5809f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00062-of-00080.parquet:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51d25dea7c14e7faba7f48e1d470a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00063-of-00080.parquet:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1226c5dfe8484ba9d12e716e0bddc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00064-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca23eda2a584f5f9e8c2bfdd5d4e57b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00065-of-00080.parquet:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0eac391cf914ff48b6690357d54bbf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00066-of-00080.parquet:   0%|          | 0.00/300M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de806a763ff4c31b70212cf42c6ffd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00067-of-00080.parquet:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c064b351e036473e8bd31532bd0e62d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00068-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4577580fba446d9912b7c2c84e8e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00069-of-00080.parquet:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0459780a714b38a9c8c196523d8cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00070-of-00080.parquet:   0%|          | 0.00/300M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62396a312c843299588b57821afa10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00071-of-00080.parquet:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac578aea72c4c399e5fafb2b9c535e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00072-of-00080.parquet:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d42862338740668ea8143ef0ab0cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00073-of-00080.parquet:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223fc510aff34857bd3a247c6926d22d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00074-of-00080.parquet:   0%|          | 0.00/300M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7fabf4388e74a3084cb1ab85dc26b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00075-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff4a553e10849e0a41bdf4bded523ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00076-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13190b30e3a14112ba56cb9d90ad8cbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00077-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28eb68b9e35f4dd687d43bceb0393189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00078-of-00080.parquet:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8fae18d96df4650a36ee9772e7c45b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00079-of-00080.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5b316a18c24f04b80af44a5d74bc4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8013769 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae8ce515bdf470db35e78220d19b3ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: openwebtext / split=train\n",
      "Loaded sample size: 2000\n",
      "Example preview (first 500 chars):\n",
      "Port-au-Prince, Haiti (CNN) -- Earthquake victims, writhing in pain and grasping at life, watched doctors and nurses walk away from a field hospital Friday night after a Belgian medical team evacuated the area, saying it was concerned about security.\n",
      "\n",
      "The decision left CNN Chief Medical Correspondent Sanjay Gupta as the only doctor at the hospital to get the patients through the night.\n",
      "\n",
      "CNN initially reported, based on conversations with some of the doctors, that the United Nations ordered the B\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "\n",
    "CACHE_DIR = \"dataset/hf_cache\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "DATASET_NAME = \"Skylion007/openwebtext\"\n",
    "SPLIT = \"train\"\n",
    "SAMPLE_SIZE = 2000  # adjust if needed\n",
    "\n",
    "ds = None\n",
    "try:\n",
    "    ds = load_dataset(DATASET_NAME, split=SPLIT, cache_dir=CACHE_DIR, streaming=False)\n",
    "except Exception as exc:\n",
    "    print(f\"Falling back to openwebtext because {exc}\")\n",
    "    try:\n",
    "        DATASET_NAME = \"openwebtext\"\n",
    "        ds = load_dataset(DATASET_NAME, split=SPLIT, cache_dir=CACHE_DIR, streaming=False)\n",
    "    except Exception as exc2:\n",
    "        raise RuntimeError(f\"Could not load either dataset: {exc2}\") from exc\n",
    "\n",
    "n = min(SAMPLE_SIZE, len(ds))\n",
    "ds_subset = ds.select(range(n))\n",
    "samples = ds_subset[\"text\"]\n",
    "\n",
    "print(f\"Dataset: {DATASET_NAME} / split={SPLIT}\")\n",
    "print(f\"Loaded sample size: {len(samples)}\")\n",
    "print(\"Example preview (first 500 chars):\")\n",
    "print(samples[0][:500] if samples else \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbedcbd",
   "metadata": {},
   "source": [
    "### EDA of RAW Datset\n",
    "\n",
    "We utilize the functions tooken from the service/explore_service.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44b23e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad831573ff1424a831ab5fa6d191b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e26a792ea44eb8bbab8c0ef6000848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e9e766dd5c48da9abe0efe53739fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from service.explore_service import load_samples\n",
    "\n",
    "# Load samples with fallback and caching\n",
    "samples, resolved = load_samples(\n",
    "    dataset_name=\"openwebtext\",\n",
    "    split=\"train\",\n",
    "    sample_size=2000,\n",
    "    cache_dir=\"dataset/hf_cache\",\n",
    "    streaming=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bfc7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b36f79c5fec4cd5873b096b4eab2d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f090c10b5d4e70b04c301f0676c5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb1e1e7a416479dbc4f4d23087f66e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/80 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e2ba20b08740b581bea55a01869b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8013769 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda4c23c7acb44e09eb9976af482795a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset: openwebtext, samples: 2000\n"
     ]
    }
   ],
   "source": [
    "from service.explore_service import (\n",
    "    length_stats,\n",
    "    token_stats,\n",
    "    flag_counts,\n",
    "    duplicate_stats,\n",
    "    full_eda_report,\n",
    ")\n",
    "\n",
    "# Basic EDA\n",
    "print(length_stats(samples))\n",
    "print(token_stats(samples, tokenizer_name=\"gpt2\", max_samples=2000))\n",
    "print(flag_counts(samples))\n",
    "print(duplicate_stats(samples))\n",
    "print(full_eda_report(samples))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9706ecf2",
   "metadata": {},
   "source": [
    "## Pre-processing of Dataset\n",
    "\n",
    "We use preprocessing_utils functions to apply data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ed03ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q transformers langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b828876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "CACHE_DIR = \"dataset/hf_cache\"          # existing cache\n",
    "OUT_PATH = pathlib.Path(\"dataset_final/openwebtext_clean.jsonl\")\n",
    "DATASET_NAME = \"NLP26_OpenWebText\"      # falls back to openwebtext if missing\n",
    "FALLBACK_NAME = \"openwebtext\"\n",
    "SPLIT = \"train\"\n",
    "MAX_TOKENS = 2048                       # truncate to GPT-2 block\n",
    "MIN_CHARS = 50\n",
    "MAX_CHARS = 100_000\n",
    "DROP_CODE = True\n",
    "DROP_NON_EN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86b52bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c46afe8d384976a659b5c01b2953eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b008e3a834f4ee9bdb0b0b2545e8bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing openwebtext: 1it [00:02,  2.70s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2095 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Processing openwebtext: 109193it [15:54, 114.43it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 49\u001b[0m\n\u001b[0;32m     47\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     48\u001b[0m raw \u001b[38;5;241m=\u001b[39m ex\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 49\u001b[0m cleaned \u001b[38;5;241m=\u001b[39m preprocess_text(\n\u001b[0;32m     50\u001b[0m     raw,\n\u001b[0;32m     51\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtok \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tok, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     52\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39mMAX_TOKENS,\n\u001b[0;32m     53\u001b[0m     drop_code\u001b[38;5;241m=\u001b[39mDROP_CODE,\n\u001b[0;32m     54\u001b[0m     drop_non_english\u001b[38;5;241m=\u001b[39mDROP_NON_EN,\n\u001b[0;32m     55\u001b[0m     url_placeholder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<url>\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     56\u001b[0m     min_chars\u001b[38;5;241m=\u001b[39mMIN_CHARS,\n\u001b[0;32m     57\u001b[0m     max_chars\u001b[38;5;241m=\u001b[39mMAX_CHARS,\n\u001b[0;32m     58\u001b[0m )\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cleaned:\n\u001b[0;32m     60\u001b[0m     filtered_clean \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\JustS\\OneDrive\\Документы\\University Projects\\PikoGPT_Template\\utils\\preprocessing_utils.py:129\u001b[0m, in \u001b[0;36mpreprocess_text\u001b[1;34m(text, tokenizer, max_tokens, drop_code, drop_non_english, url_placeholder, min_chars, max_chars)\u001b[0m\n\u001b[0;32m    122\u001b[0m         text = truncate_tokens(text, tokenizer, max_tokens)\n\u001b[0;32m    124\u001b[0m     return text if text else None\n\u001b[0;32m    127\u001b[0m def preprocess_batch(\n\u001b[0;32m    128\u001b[0m     texts: Sequence[str],\n\u001b[1;32m--> 129\u001b[0m     *,\n\u001b[0;32m    130\u001b[0m     tokenizer=None,\n\u001b[0;32m    131\u001b[0m     max_tokens: Optional[int] = None,\n\u001b[0;32m    132\u001b[0m     drop_code: bool = True,\n\u001b[0;32m    133\u001b[0m     drop_non_english: bool = True,\n\u001b[0;32m    134\u001b[0m     url_placeholder: str = \"<url>\",\n\u001b[0;32m    135\u001b[0m     min_chars: int = 50,\n\u001b[0;32m    136\u001b[0m     max_chars: int = 100_000,\n\u001b[0;32m    137\u001b[0m ) -> List[str]:\n\u001b[0;32m    138\u001b[0m     \"\"\"Preprocess a batch and drop filtered items.\"\"\"\n\u001b[0;32m    139\u001b[0m     cleaned: List[str] = []\n",
      "File \u001b[1;32mc:\\Users\\JustS\\OneDrive\\Документы\\University Projects\\PikoGPT_Template\\utils\\preprocessing_utils.py:91\u001b[0m, in \u001b[0;36mtruncate_tokens\u001b[1;34m(text, tokenizer, max_tokens)\u001b[0m\n\u001b[0;32m     87\u001b[0m     ids = ids[:max_tokens]\n\u001b[0;32m     88\u001b[0m     return tokenizer.decode(ids)\n\u001b[1;32m---> 91\u001b[0m # ---------- Core preprocess ----------\n\u001b[0;32m     93\u001b[0m def preprocess_text(\n\u001b[0;32m     94\u001b[0m     text: str,\n\u001b[0;32m     95\u001b[0m     *,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m     max_chars: int = 100_000,\n\u001b[0;32m    103\u001b[0m ) -> Optional[str]:\n\u001b[0;32m    104\u001b[0m     \"\"\"Apply a sequence of cleaning steps; return None if filtered out.\"\"\"\n",
      "File \u001b[1;32mc:\\Users\\JustS\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2222\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, padding_side, return_tensors, **kwargs)\u001b[0m\n\u001b[0;32m   2213\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   2214\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   2215\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   2216\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   2217\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2218\u001b[0m )\n\u001b[0;32m   2220\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(kwargs_updated)\n\u001b[1;32m-> 2222\u001b[0m encoded_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_plus(\n\u001b[0;32m   2223\u001b[0m     text,\n\u001b[0;32m   2224\u001b[0m     text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   2225\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   2226\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[0;32m   2227\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   2228\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   2229\u001b[0m     stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m   2230\u001b[0m     padding_side\u001b[38;5;241m=\u001b[39mpadding_side,\n\u001b[0;32m   2231\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m   2232\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2233\u001b[0m )\n\u001b[0;32m   2235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoded_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\JustS\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_tokenizers.py:861\u001b[0m, in \u001b[0;36mTokenizersBackend._encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode_special_tokens \u001b[38;5;241m=\u001b[39m split_special_tokens\n\u001b[0;32m    860\u001b[0m \u001b[38;5;66;03m# Direct rust backend call\u001b[39;00m\n\u001b[1;32m--> 861\u001b[0m encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode_batch(\n\u001b[0;32m    862\u001b[0m     batch_text_or_text_pairs,\n\u001b[0;32m    863\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m    864\u001b[0m     is_pretokenized\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m    865\u001b[0m )\n\u001b[0;32m    867\u001b[0m \u001b[38;5;66;03m# Convert encodings to BatchEncoding format\u001b[39;00m\n\u001b[0;32m    868\u001b[0m tokens_and_encodings \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_encoding(\n\u001b[0;32m    870\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    879\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[0;32m    880\u001b[0m ]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import json, re\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import importlib\n",
    "\n",
    "import utils.preprocessing_utils as pu\n",
    "importlib.reload(pu)\n",
    "\n",
    "from utils.preprocessing_utils import preprocess_text, load_tokenizer, load_test_sentences\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Optional test sets for leakage removal (put actual paths)\n",
    "TEST_PATHS = [\n",
    "    \"path/to/wikitext_test.txt\",        # replace with real path or leave empty\n",
    "    \"path/to/nlp26_eval.txt\",\n",
    "]\n",
    "\n",
    "# Load tokenizer (gracefully handles missing pkg)\n",
    "tok = AutoTokenizer.from_pretrained(\"gpt2\", model_max_length=MAX_TOKENS, truncation_side=\"right\")\n",
    "\n",
    "# Load test sentences (can be empty if files not present)\n",
    "test_sents = load_test_sentences(TEST_PATHS)\n",
    "\n",
    "def has_overlap(text: str, test_set: set) -> bool:\n",
    "    if not test_set:\n",
    "        return False\n",
    "    sents = re.split(r\"(?<=[.!?])\\s+\", text.strip())\n",
    "    norm = {re.sub(r\"\\s+\", \" \", s.lower()).strip() for s in sents if s.strip()}\n",
    "    return bool(norm & test_set)\n",
    "\n",
    "# Prepare output\n",
    "OUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Stream dataset (downloads first time only; otherwise uses cache)\n",
    "try:\n",
    "    ds = load_dataset(DATASET_NAME, split=SPLIT, cache_dir=CACHE_DIR, streaming=True)\n",
    "    resolved = DATASET_NAME\n",
    "except Exception:\n",
    "    ds = load_dataset(FALLBACK_NAME, split=SPLIT, cache_dir=CACHE_DIR, streaming=True)\n",
    "    resolved = FALLBACK_NAME\n",
    "\n",
    "MAX_DOCS = 100_000  # change as needed (e.g., 50_000)\n",
    "\n",
    "total = kept = filtered_overlap = filtered_clean = 0\n",
    "\n",
    "with OUT_PATH.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for ex in tqdm(ds, desc=f\"Processing {resolved}\"):\n",
    "        if total >= MAX_DOCS:\n",
    "            break\n",
    "        total += 1\n",
    "        raw = ex.get(\"text\", \"\")\n",
    "        cleaned = preprocess_text(\n",
    "            raw,\n",
    "            tokenizer=tok if not isinstance(tok, Exception) else None,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            drop_code=DROP_CODE,\n",
    "            drop_non_english=DROP_NON_EN,\n",
    "            url_placeholder=\"<url>\",\n",
    "            min_chars=MIN_CHARS,\n",
    "            max_chars=MAX_CHARS,\n",
    "        )\n",
    "        if not cleaned:\n",
    "            filtered_clean += 1\n",
    "            continue\n",
    "        if has_overlap(cleaned, test_sents):\n",
    "            filtered_overlap += 1\n",
    "            continue\n",
    "        json.dump({\"text\": cleaned}, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")\n",
    "        kept += 1\n",
    "\n",
    "print(f\"Dataset: {resolved}\")\n",
    "print(f\"Total seen: {total}\")\n",
    "print(f\"Kept: {kept}\")\n",
    "print(f\"Filtered (clean rules): {filtered_clean}\")\n",
    "print(f\"Filtered (overlap): {filtered_overlap}\")\n",
    "print(f\"Output: {OUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cc9e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from utils.explore_utils import (\n",
    "    length_stats,\n",
    "    token_stats,\n",
    "    flag_counts,\n",
    "    duplicate_stats,\n",
    ")  # if you prefer, you can copy the simple EDA functions inline\n",
    "\n",
    "CLEAN_JSONL = str(OUT_PATH)  # same path as you wrote above\n",
    "EDA_SAMPLE = 5000            # adjust sample size for speed\n",
    "\n",
    "eda_ds = load_dataset(\"json\", data_files=CLEAN_JSONL, split=\"train[:{}]\".format(EDA_SAMPLE))\n",
    "texts = eda_ds[\"text\"]\n",
    "\n",
    "print(length_stats(texts))\n",
    "print(token_stats(texts, tokenizer_name=\"gpt2\", max_samples=EDA_SAMPLE))\n",
    "print(flag_counts(texts))\n",
    "print(duplicate_stats(texts))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
