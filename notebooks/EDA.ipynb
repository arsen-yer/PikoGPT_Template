{
    "nbformat":  4,
    "metadata":  {
                     "kernelspec":  {
                                        "language":  "python",
                                        "display_name":  "Python 3",
                                        "name":  "python3"
                                    },
                     "language_info":  {
                                           "version":  "3.11",
                                           "name":  "python"
                                       }
                 },
    "nbformat_minor":  5,
    "cells":  [
                  {
                      "source":  [
                                     "# EDA: NLP26 OpenWebText (local download)`n",
                                     "Load the course split locally (no streaming), cache under dataset/, and inspect a small subset for cleaning decisions.`n"
                                 ],
                      "cell_type":  "markdown",
                      "metadata":  {

                                   }
                  },
                  {
                      "outputs":  [

                                  ],
                      "source":  [
                                     "%pip install -q datasets tiktoken`n"
                                 ],
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   }
                  },
                  {
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import os\\n",
                                     "from datasets import load_dataset\\n",
                                     "import re\\n",
                                     "\\n",
                                     "CACHE_DIR = \"dataset/hf_cache\"\\n",
                                     "os.makedirs(CACHE_DIR, exist_ok=True)\\n",
                                     "\\n",
                                     "DATASET_NAME = \"NLP26_OpenWebText\"  # course split; use \"openwebtext\" if unavailable\\n",
                                     "SPLIT = \"train\"\\n",
                                     "SAMPLE_SIZE = 2000  # adjust if needed\\n",
                                     "\\n",
                                     "try:\\n",
                                     "    ds = load_dataset(DATASET_NAME, split=SPLIT, cache_dir=CACHE_DIR, streaming=False)\\n",
                                     "except Exception as exc:\\n",
                                     "    print(f\"Falling back to openwebtext because {exc}\")\\n",
                                     "    DATASET_NAME = \"openwebtext\"\\n",
                                     "    ds = load_dataset(DATASET_NAME, split=SPLIT, cache_dir=CACHE_DIR, streaming=False)\\n",
                                     "\\n",
                                     "# take a subset into memory\\n",
                                     "ds = ds.select(range(min(SAMPLE_SIZE, len(ds))))\\n",
                                     "samples = ds[\"text\"]\\n",
                                     "\\n",
                                     "print(f\"Dataset: {DATASET_NAME} / split={SPLIT}\")\\n",
                                     "print(f\"Loaded sample size: {len(samples)}\")\\n",
                                     "print(\"Example preview (first 500 chars):\")\\n",
                                     "print(samples[0][:500] if samples else \"\")\\n"
                                 ],
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   }
                  },
                  {
                      "outputs":  [

                                  ],
                      "source":  [
                                     "lengths = [len(t) for t in samples]\\n",
                                     "if lengths:\\n",
                                     "    avg_len = sum(lengths) / len(lengths)\\n",
                                     "    print(\"Min/Max/Avg length:\", min(lengths), max(lengths), avg_len)\\n",
                                     "    short = sum(1 for l in lengths if l \u003c 200)\\n",
                                     "    print(f\"Short samples (\u003c200 chars): {short} ({100*short/len(lengths):.1f}%)\")\\n",
                                     "else:\\n",
                                     "    print(\"No samples loaded\")\\n",
                                     "\\n",
                                     "html_re = re.compile(r\"\u003c[^\u003e]+\u003e\")\\n",
                                     "code_markers = [\"```\", \"{\", \"}\", \";\", \"def \", \"class \", \"#include\", \"import \"]\\n",
                                     "\\n",
                                     "def looks_like_code(text: str) -\u003e bool:\\n",
                                     "    if \"```\" in text:\\n",
                                     "        return True\\n",
                                     "    brace_count = text.count(\"{\") + text.count(\"}\")\\n",
                                     "    if brace_count \u003e= 10:\\n",
                                     "        return True\\n",
                                     "    return sum(1 for m in code_markers if m in text) \u003e= 3\\n",
                                     "\\n",
                                     "def non_english_hint(text: str) -\u003e bool:\\n",
                                     "    if not text:\\n",
                                     "        return False\\n",
                                     "    non_ascii = sum(1 for ch in text if ord(ch) \u003e 127)\\n",
                                     "    return (non_ascii / len(text)) \u003e 0.2\\n",
                                     "\\n",
                                     "html_count = sum(1 for t in samples if html_re.search(t))\\n",
                                     "code_count = sum(1 for t in samples if looks_like_code(t))\\n",
                                     "non_en_count = sum(1 for t in samples if non_english_hint(t))\\n",
                                     "\\n",
                                     "print(\"Samples with HTML tags:\", html_count)\\n",
                                     "print(\"Samples that look like code:\", code_count)\\n",
                                     "print(\"Samples with non-English signals:\", non_en_count)\\n"
                                 ],
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   }
                  }
              ]
}
